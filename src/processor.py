"""
Author: PumpkinğŸƒ
Date:2025-11-07
Description: å›¾å¤„ç†æ¨¡å—
"""

import json
import time
import warnings
from typing import List, Union
import numpy as np
import pandas as pd
import scipy.sparse as sp
from sklearn.metrics import pairwise_distances


def is_consecutive(lst: List[int]) -> bool:
    if not lst:  # å¦‚æœåˆ—è¡¨ä¸ºç©º
        return False

    # æ’åºåˆ—è¡¨
    lst = list(set(lst))
    lst_sorted = sorted(lst)

    # æ£€æŸ¥ç›¸é‚»å…ƒç´ å·®æ˜¯å¦ä¸º 1
    for i in range(1, len(lst_sorted)):
        if lst_sorted[i] - lst_sorted[i - 1] != 1:
            return False

    return True


def is_sparse_based_on_density(matrix: np.ndarray, threshold: float = 0.9) -> bool:
    # åˆ¤æ–­çŸ©é˜µæ˜¯å¦ä¸ºç¨€ç–
    # è®¡ç®—é›¶å…ƒç´ çš„æ¯”ä¾‹
    zero_count = np.sum(matrix == 0)
    total_elements = matrix.size
    zero_density = zero_count / total_elements
    return zero_density > threshold


def edge_process(
    dataname: str, undirected: bool = True, sparsity_threshold: float = 0.9
) -> Union[np.ndarray, sp.csr_matrix]:
    edges_file = f"data/graphs/{dataname}.edges"
    edges = pd.read_csv(edges_file, header=None)
    edges.columns = ["id1", "id2"]

    edges = edges.to_numpy()

    n = edges.max() + 1
    adj = np.zeros((n, n))

    for u, v in edges:
        adj[u, v] = 1
        if undirected:
            adj[v, u] = 1

    # æ ¹æ®é›¶å…ƒç´ çš„å¯†åº¦åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬æ¢ä¸ºç¨€ç–çŸ©é˜µ
    if is_sparse_based_on_density(adj, sparsity_threshold):
        adj = sp.csr_matrix(adj)  # è½¬æ¢ä¸ºç¨€ç–çŸ©é˜µï¼ˆCSRæ ¼å¼ï¼‰
        print("é‚»æ¥çŸ©é˜µè½¬æ¢ä¸ºç¨€ç–çŸ©é˜µ")

    return adj


def feature_process(
    dataname: str, sigma: float = 0.5, sparsity_threshold: float = 0.9
) -> np.ndarray:
    features_file = f"data/graphs/{dataname}.features"

    with open(features_file, "r") as f:
        features_data = json.load(f)
        nodes = list(features_data.keys())

    num_nodes = len(nodes)

    # è·å–æ‰€æœ‰ç‰¹å¾çš„æœ€å¤§ç´¢å¼•å€¼ï¼Œç¡®å®šç‰¹å¾æ€»æ•°
    all_features = sorted([f for features in features_data.values() for f in features])
    if not is_consecutive(all_features):
        warnings.warn("ç‰¹å¾ç´¢å¼•ä¸æ˜¯è¿ç»­çš„æ•´æ•°ï¼Œå¯èƒ½ä¼šå¯¼è‡´é”™è¯¯")

    num_features = max(all_features) + 1  # å› ä¸ºç‰¹å¾ä» 0 å¼€å§‹ç´¢å¼•

    # åˆ›å»ºç¨€ç–ç‰¹å¾çŸ©é˜µ
    features = np.zeros((num_nodes, num_features))
    for i, node in enumerate(nodes):
        for feature in features_data[node]:
            features[i, feature] = 1

    # æ ¹æ®é›¶å…ƒç´ çš„å¯†åº¦åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬æ¢ä¸ºç¨€ç–çŸ©é˜µ
    if is_sparse_based_on_density(features, sparsity_threshold):
        features = sp.csr_matrix(features)  # è½¬æ¢ä¸ºç¨€ç–çŸ©é˜µï¼ˆCSRæ ¼å¼ï¼‰
        print("ç‰¹å¾çŸ©é˜µè½¬æ¢ä¸ºç¨€ç–çŸ©é˜µ")

    # è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦çŸ©é˜µ
    if sp.issparse(features):
        features_sq = features.power(2).sum(axis=1).A1
        dot_product = features @ features.T
        dists_sq = (
            features_sq[:, None] + features_sq[None, :] - 2 * dot_product.toarray()
        )
    else:
        dists_sq = pairwise_distances(features, metric="sqeuclidean")

    similarity_matrix = np.exp(-sigma * dists_sq)
    # æ£€æŸ¥ç›¸ä¼¼åº¦çŸ©é˜µä¸­çš„ NaN å’Œ inf å€¼
    if np.any(np.isnan(similarity_matrix)) or np.any(np.isinf(similarity_matrix)):
        warnings.warn("ç›¸ä¼¼åº¦çŸ©é˜µä¸­åŒ…å« NaN æˆ– inf å€¼ï¼")

    return similarity_matrix


def high_order(
    term: Union[np.ndarray, sp.csr_matrix], order: int = 2, decay: float = 0.5
) -> np.ndarray:
    if sp.issparse(term):  # å¦‚æœæ˜¯ç¨€ç–çŸ©é˜µ
        ho_matrix = sp.csr_matrix(term.shape, dtype=np.float32)  # åˆå§‹åŒ–é«˜é˜¶çŸ©é˜µ
        matrix_power = term.copy()  # å½“å‰çŸ©é˜µçš„å¹‚ï¼Œåˆå§‹ä¸º term
        factorial = 1.0
        for i in range(1, order + 1):
            factorial *= i
            ho_matrix += matrix_power.multiply(decay**i / factorial)  # ç´¯åŠ é«˜é˜¶é¡¹
            matrix_power = matrix_power @ term  # æ›´æ–°çŸ©é˜µçš„å¹‚
    else:  # å¦‚æœæ˜¯ç¨ å¯†çŸ©é˜µ
        ho_matrix = np.zeros_like(term, dtype=np.float32)  # åˆå§‹åŒ–é«˜é˜¶çŸ©é˜µ
        matrix_power = term.copy()  # å½“å‰çŸ©é˜µçš„å¹‚ï¼Œåˆå§‹ä¸º term
        factorial = 1.0
        for i in range(1, order + 1):
            factorial *= i
            ho_matrix += matrix_power * (decay**i / factorial)  # ç´¯åŠ é«˜é˜¶é¡¹
            matrix_power = matrix_power @ term  # æ›´æ–°çŸ©é˜µçš„å¹‚
    if sp.issparse(ho_matrix):
        ho_matrix = ho_matrix.toarray()
    return ho_matrix


if __name__ == "__main__":
    t = time.time()
    edge_process("citeseer")
    print(f"é‚»æ¥çŸ©é˜µå¤„ç†è€—æ—¶: {time.time() - t}")
    t = time.time()
    feature_process("citeseer")
    print(f"ç‰¹å¾çŸ©é˜µå¤„ç†è€—æ—¶: {time.time() - t}")
    t = time.time()
    high_order(edge_process("citeseer"))
    print(f"é«˜é˜¶ä¼ æ’­çŸ©é˜µå¤„ç†è€—æ—¶: {time.time() - t}")
